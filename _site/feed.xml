<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-02-25T14:47:06+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jinlu Zhang’s Blog</title><subtitle>My Website with Blogs, Publications, Projects and Resume...&gt;</subtitle><author><name>Jinlu Zhang</name><email>Jinluzhang1126@163.com</email></author><entry><title type="html">问题解决：Github图片无法访问</title><link href="http://localhost:4000/2020/02/25/github-img-not-available.html" rel="alternate" type="text/html" title="问题解决：Github图片无法访问" /><published>2020-02-25T00:00:00+08:00</published><updated>2020-02-25T00:00:00+08:00</updated><id>http://localhost:4000/2020/02/25/github-img-not-available</id><content type="html" xml:base="http://localhost:4000/2020/02/25/github-img-not-available.html">&lt;h2 id=&quot;需求&quot;&gt;需求&lt;/h2&gt;

&lt;p&gt;最近发现在墙内无法顺畅的访问github远程仓库中的图片，导致自己的博客中的图片全都裂开了。。。
&lt;!--more--&gt;
之前的访问方式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;找到github远程库中的图片，复制图片链接，格式一般是这样的：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://raw.githubusercontent.com/username/repo_name/img_name...&lt;/code&gt;，&lt;/li&gt;
  &lt;li&gt;在markdown文档中嵌入图片链接&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;现在的情况是这样的:cry:：&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200225115717536.png&quot; alt=&quot;image-20200225115717536&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;原因分析&quot;&gt;原因分析&lt;/h2&gt;

&lt;p&gt;github的服务器是在国外的，对于一些文字代码信息还可以预览编辑，但是图片却无法在线访问，如果切换到外网是可以访问的非常丝滑的，那么基本就是防火墙的问题了。但是博客对其他访问者是开放的，总不能让所有人都去翻翻翻。。。&lt;/p&gt;

&lt;h2 id=&quot;解决方案&quot;&gt;解决方案&lt;/h2&gt;

&lt;p&gt;经过上下求索，找到了一个可靠长久的解决方法，特别是针对那些有写博客需求的人。&lt;/p&gt;

&lt;p&gt;我们需要给网站配置一个分流配置，具体原理不赘述，我的理解也不深，大致就是加了一个分流中转，让访问&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;https://raw.githubusercontent.com/username/repo_name/img_name...&lt;/code&gt;这个地址的人先访问国内的域名，然后通过DNS转到这个真实的地址&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;建立一个GitHub图片库，注意要设置为共有，以后图片都放到这里面&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200225121128297.png&quot; alt=&quot;image-20200225121128297&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;开启github pages功能，branch选中 master 就行&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200225144538660.png&quot; alt=&quot;image-20200225144538660&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;图中因为我配了一个域名，所以直接显示了域名，如果没有自己的域名就是github.io&lt;/li&gt;
  &lt;li&gt;直接访问域名+图片路径，以http://jinluzhang.site/PublicPic/Pic/image-20200225121128297.png为例，就会显示了，在markdown嵌入即可。&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Jinlu Zhang</name><email>Jinluzhang1126@163.com</email></author><category term="enviroment-setup," /><category term="bug" /><summary type="html">需求 最近发现在墙内无法顺畅的访问github远程仓库中的图片，导致自己的博客中的图片全都裂开了。。。</summary></entry><entry><title type="html">SSD Single Shot MultiBox Detector</title><link href="http://localhost:4000/2020/02/22/SSD-Single-Shot-MultiBox-Detector.html" rel="alternate" type="text/html" title="SSD Single Shot MultiBox Detector" /><published>2020-02-22T00:00:00+08:00</published><updated>2020-02-22T00:00:00+08:00</updated><id>http://localhost:4000/2020/02/22/SSD-Single-Shot-MultiBox-Detector</id><content type="html" xml:base="http://localhost:4000/2020/02/22/SSD-Single-Shot-MultiBox-Detector.html">&lt;blockquote&gt;
  &lt;p&gt;目标检测中的一个经典one-stage算法——SSD，ECCV2016中Wei Liu提出的，相比于YOLO针对于小目标检测更友好。文章基本按照论文行文思路和结构记笔记，最后给出一个sumary&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;https://link.springer.com/chapter/10.1007%2F978-3-319-46448-0_2&quot;&gt;论文地址&lt;/a&gt;  &lt;a href=&quot;https://github.com/balancap/SSD-Tensorflow&quot;&gt;代码地址&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;参考：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58713034&quot;&gt;SSD论文笔记&lt;/a&gt;,&lt;/p&gt;

  &lt;!--more--&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;本文提出了一种使用单个深度神经网络来检测图像中的目标的方法，便于训练与优化，同时提高检测速度。&lt;strong&gt;将边界框的输出空间离散化为不同长宽比的一组default box，这些box是通过不同尺寸（分辨率）layer上的feature map得出的，每一层都具有不同的aspect ratios and scales&lt;/strong&gt;。在预测阶段，网络会在每个默认框中分别为每个类别生成分数，并对default box进行微调以更好地匹配目标形状。此外，网络还结合了&lt;strong&gt;不同分辨率的多个特征映射&lt;/strong&gt;的预测，自然地处理各种尺寸的目标。相对于region proposal的方法，SSD非常简单，因为它完全消除了提出生成和随后的像素或特征重采样阶段，并&lt;strong&gt;将所有计算封装到单个网络&lt;/strong&gt;中。&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;目前主流的目标检测算法分为两种，一种R-CNN流，主要思路是先使用选择性搜索之类的启发式方法（Selective Search）或CNN网络（RPN）生成region proposal，然后在此proposal上生成特征输入到分类和定位网络中，这类方法是&lt;strong&gt;two-stage&lt;/strong&gt;的，特点是精度高、速度略慢、训练较复杂；第二种是YOLO为代表的&lt;strong&gt;one-stage&lt;/strong&gt;流，它们的思路是均匀地在图片的不同位置进行密集抽样，抽样时可以采用不同的尺度和长宽比，然后利用CNN提取特征后直接进行分类和回归，整个过程只需要一步，所以它们的优势是速度快。但是均匀的密集采样有一个缺点就是正样本和负样本分布极不均衡，这会导致训练困难，导致模型准确度稍低。&lt;strong&gt;（可以通过FocalLoss缓解这个问题）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;由于改进了backbone网络，并且使用了不同分辨率的feature map，所以相比于YOLO流更加准确，尤其是对小物体检测敏感，速度也比faster rcnn更快。SSD属于one-stage，所以本文主要比较的也是YOLO流。&lt;/p&gt;

&lt;p&gt;原文这段话感觉概括了SSD的有别于其他方法的主要思想：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Our improvements include using a small convolutional filter to predict object
categories and offsets in bounding box locations, using separate predictors (filters) for
different aspect ratio detections, and applying these filters to multiple feature maps from
the later stages of a network in order to perform detection at multiple scales&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;使用VGG这种小卷积核网络进行提取初始目标特征和偏移量，并且针对不同尺度的feature maps产生不同的filter，然后将这种filter应用于之后的detection阶段。&lt;/p&gt;

&lt;h2 id=&quot;the-single-shot-detector-ssd-网络结构&quot;&gt;The Single Shot Detector (SSD)-网络结构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200209121221893.png&quot; alt=&quot;image-20200209121221893&quot; style=&quot;zoom:150%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;网络的输入是300 x 300，称为SSD300；除此之外还有输入为500 x 500的SSD500，它在SSD300的基础上又加了一层conv11_2用于检测。&lt;/p&gt;

&lt;p&gt;SSD将VGG-16的全连接层fc6和fc7转换成3 x 3的卷积层Conv6和1 x 1的卷积层Conv7，并将pool5从2 x 2 - s2转换成3 x 3 - s1。第一个用于检测的feature map是Conv4_3，由于位置靠前，为了避免与后面的检测层差异太大，所以在Conv4_3后面使用L2 normalization，即仅对每个像素点在channel维度上进行归一化。&lt;/p&gt;

&lt;p&gt;可以看出，相比于YOLO网络，SSD主要改进在于：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;VGG16作为特征提取网络；&lt;/li&gt;
  &lt;li&gt;使用不同尺寸的feature map提取出来的不同尺寸和长宽比的default box进行检测和分类。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;模型关键点&quot;&gt;模型关键点&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;多尺度feature map预测&lt;/strong&gt;，&lt;strong&gt;SSD网络中分为了6个stage，每个stage能学习到一个特征图，然后进行边框回归和分类&lt;/strong&gt;，这些层的尺寸&lt;strong&gt;逐渐减小&lt;/strong&gt;，并允许&lt;strong&gt;多尺度&lt;/strong&gt;的预测。在Conv4_3、Conv6、Conv7、Conv8_2、Conv9_2、Conv10_2、Pool 11的feature map上都会进行检测，入到后面的&lt;em&gt;detection per class&lt;/em&gt;层， 提取出来类别概率和坐标：（c, x, y, w, h）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;VGG网络作为特征提取网络&lt;/strong&gt;，去除最后两层FC层，改为3 x 3的卷积层Conv6和1 x 1的卷积层Conv7，并在之后增加尺寸依次减小的4个卷积层&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;使用CNN检测&lt;/strong&gt;，这一部分和Faster RCNN中的RPN网络有些类似，对于feature map先使用3 x 3卷积，卷积后的结果代表feature map上每个像素代表的default box的信息，如类别概率或位置信息。&lt;/p&gt;

    &lt;p&gt;对于边框回归，只需要&lt;strong&gt;4维向量&lt;/strong&gt;即可，分别代表边框缩放尺度(坐标轴两个方向)和平移向量(坐标轴两个方向)。对于分类，SSD网络采取为每个类别进行打分的策略，也就是说对于每个Default Box，SSD网络会计算出相应的&lt;strong&gt;每个类别的分数&lt;/strong&gt;。假设数据集类别数为c，加上背景，那么总的类别数就是&lt;strong&gt;c+1&lt;/strong&gt;类。SSD网络采用了c+1维向量来分别代表该Default Box对于每个类别所得到的分数。这里，假设是VOC数据集，那么每个Default Box将生成一个20 + 1 + 4 = 25维的特征向量。同样，以Conv9输出特征图5x5为例。抽象地说特征向量就是：&lt;strong&gt;(m*n)*k*(c+4)&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/MgVSAo8.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Default boxes and aspect ratios&lt;/strong&gt;，feature map上每个像素都会生成多个default box。作者充分的吸取了Faster R-CNN中的Anchors机制，在每个Stage中根据Feature Map的大小，按照固定的Scale和Radio生成Default Boxes。这里为了方便阐述，选取了Conv9的Feature Map，输出大小为5x5。SSD网络中作者设置Conv9的每个点默认生成6个box，如下图所示。因此在这一层上，共生成了5x5x6=150个boxes。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/pToKpCA.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;（👆这段解释来自👉&lt;a href=&quot;https://blog.csdn.net/neu_chenguangq/article/details/79057655&quot;&gt;here&lt;/a&gt;,感觉解释的很到位，特此说明）&lt;/p&gt;

&lt;p&gt;这样在不同尺度生成default box最大的好处在于可以对各种尺度和形状的物体进行预测：下图中狗的ground truth和4 x 4 feature map中default box匹配，但和8 x 8 feature map的任何一个default box都不匹配，所以SSD相对于RPN考虑更周到&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200222105802543.png&quot; alt=&quot;image-20200222105802543&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;注意区分dafault-box生成和cnn检测&quot;&gt;注意区分dafault box生成和CNN检测&lt;/h3&gt;

&lt;p&gt;这两个关键点是分开的，default box生成时对于feature map中每一个像素点生成4-6个不同长宽比的box，得到的是每一个cell的不同box&lt;/p&gt;

&lt;p&gt;而CNN检测是对每一个cell（也就是像素）进行3*3卷积，得到的是特征向量&lt;/p&gt;

&lt;p&gt;这两个我在一开始读论文的时候经常搞不清&lt;/p&gt;

&lt;h3 id=&quot;训练细节&quot;&gt;训练细节&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;如何选择default box的尺寸和长宽比&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;每层特征图上的尺度的default box计算表达式如下：&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200209134820257.png&quot; alt=&quot;image-20200209134820257&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;参数：scale， aspect ratio——每个cell生成固定的scale（s）和aspect ratio（ar）的边界框&lt;/p&gt;

    &lt;p&gt;其中 Smin 为最小尺度0.2， Smax 为最大尺度0.95。&lt;/p&gt;

    &lt;p&gt;长宽比&lt;strong&gt;ar ∈ {1，2，3，1/2，1/3}&lt;/strong&gt;，&lt;/p&gt;

    &lt;p&gt;于是default box的宽和高可以通过 &lt;img src=&quot;https://www.zhihu.com/equation?tex=w_k%5Ea%3Ds_k%5Csqrt%7Ba_r%7D&quot; alt=&quot;[公式]&quot; /&gt; 和 &lt;img src=&quot;https://www.zhihu.com/equation?tex=h_k%5Ea%3Ds_k%2F%5Csqrt%7Ba_r%7D&quot; alt=&quot;[公式]&quot; /&gt; 计算，&lt;/p&gt;

    &lt;p&gt;除此之外，还增加一个长宽比为1的时候，尺度为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=s_k%27%3D%5Csqrt%7Bs_ks_%7Bk%2B1%7D%7D&quot; alt=&quot;[公式]&quot; /&gt; 的default box，所以feature map上每个像素都有6个default box，&lt;strong&gt;注意这里得到的结果都是相对于原图的比例&lt;/strong&gt;。default box中心的坐标就是像素的中心。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;匹配策略&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;训练时需要建立ground truth和default box之间的对应关系，文中主要采用best jaccard overlap。与MultiBox稍有不同的是：SSD每个ground truth可以与多个default box匹配。&lt;/p&gt;

    &lt;p&gt;分为两步：首先对于每个ground truth，找到一个与其IoU最大的default box匹配，这个default box对应的预测框就作为正样本，其余都作为负样本。但这样做会导致负样本过多，正负样本分布极其不均衡，所以还会采取第二步：对于每个ground truth，将与其IoU大于某一阈值（比如0.5）的default box都进行匹配。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200222113304807.png&quot; alt=&quot;image-20200222113304807&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;损失函数&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200222113449881.png&quot; alt=&quot;image-20200222113449881&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200222113710154.png&quot; alt=&quot;image-20200222113710154&quot; style=&quot;zoom: 50%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=N&quot; alt=&quot;[公式]&quot; /&gt; 为匹配成功的default box个数； &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Calpha&quot; alt=&quot;[公式]&quot; /&gt; 是为了权衡两者损失而设置，通过交叉验证发现设置为1更好；第一项是置信度的Softmax损失，注意还包括背景这个类别；第二项是参数化后的bounding box中心坐标、长和宽的Smooth L1损失&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;难例挖掘&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;用于预测的 feature map 上的每个点都对应有 6 个不同的 default box，绝大部分的 default box 都是负样本，导致了正负样本不平衡。在训练过程中，采用了 Hard Negative Mining 的策略（&lt;strong&gt;根据confidence loss对所有的box进行排序，使正负例的比例保持在1:3&lt;/strong&gt;） 来平衡正负样本的比率。这样做能提高4%左右。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;数据增强&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;三个选项：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;使用整张图像作为输入&lt;/li&gt;
      &lt;li&gt;使用IOU和目标物体为0.1、0.3、0.5、0.7和0.9的patch，这些patch在原图的大小的[0.1, 1]之间，相应的宽高比在[1/2, 2]之间。&lt;/li&gt;
      &lt;li&gt;随机采取一个patch&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;experiment&quot;&gt;Experiment&lt;/h2&gt;

&lt;h3 id=&quot;caffe版本&quot;&gt;Caffe版本&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;System&lt;/th&gt;
      &lt;th&gt;VOC2007 test &lt;em&gt;mAP&lt;/em&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;FPS&lt;/strong&gt; (Titan X)&lt;/th&gt;
      &lt;th&gt;Number of Boxes&lt;/th&gt;
      &lt;th&gt;Input resolution&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/ShaoqingRen/faster_rcnn&quot;&gt;Faster R-CNN (VGG16)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;73.2&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;~6000&lt;/td&gt;
      &lt;td&gt;~1000 x 600&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;http://pjreddie.com/darknet/yolo/&quot;&gt;YOLO (customized)&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;63.4&lt;/td&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;98&lt;/td&gt;
      &lt;td&gt;448 x 448&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SSD300* (VGG16)&lt;/td&gt;
      &lt;td&gt;77.2&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;8732&lt;/td&gt;
      &lt;td&gt;300 x 300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SSD512* (VGG16)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;79.8&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;24564&lt;/td&gt;
      &lt;td&gt;512 x 512&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;tf版本代码&quot;&gt;TF版本（&lt;a href=&quot;https://github.com/balancap/SSD-Tensorflow&quot;&gt;代码&lt;/a&gt;）&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Training data&lt;/th&gt;
      &lt;th&gt;Testing data&lt;/th&gt;
      &lt;th&gt;mAP&lt;/th&gt;
      &lt;th&gt;FPS&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://drive.google.com/open?id=0B0qPCUZ-3YwWZlJaRTRRQWRFYXM&quot;&gt;SSD-300 VGG-based&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;VOC07+12 trainval&lt;/td&gt;
      &lt;td&gt;VOC07 test&lt;/td&gt;
      &lt;td&gt;0.778&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B0qPCUZ-3YwWUXh4UHJrd1RDM3c/view?usp=sharing&quot;&gt;SSD-300 VGG-based&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;VOC07+12+COCO trainval&lt;/td&gt;
      &lt;td&gt;VOC07 test&lt;/td&gt;
      &lt;td&gt;0.817&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://drive.google.com/open?id=0B0qPCUZ-3YwWT1RCLVZNN3RTVEU&quot;&gt;SSD-512 VGG-based&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;VOC07+12+COCO trainval&lt;/td&gt;
      &lt;td&gt;VOC07 test&lt;/td&gt;
      &lt;td&gt;0.837&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;和YOLO一样不同类别之间共享回归器，所以易混淆相似的类别&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;对小物体的检测相对于YOLO好一点&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;比YOLOv1快且精准度高，比Faster R-CNN精度略低&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;SSD整个网络采取了one stage的思想，以此提高检测速度。并且网络中融入了Faster R-CNN中的anchors思想，并且做了特征分层提取并依次计算边框回归和分类操作。总之，这是一个延申RPN网络思想，同时又结合YOLO框架的方法。&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Jinlu Zhang</name><email>Jinluzhang1126@163.com</email></author><category term="paper" /><summary type="html">目标检测中的一个经典one-stage算法——SSD，ECCV2016中Wei Liu提出的，相比于YOLO针对于小目标检测更友好。文章基本按照论文行文思路和结构记笔记，最后给出一个sumary 论文地址 代码地址 参考：SSD论文笔记,</summary></entry><entry><title type="html">Ubuntu18.04重装Nvidia驱动，cuda和cudnn，多用户使用anaconda</title><link href="http://localhost:4000/2020/02/17/Ubuntu18.04-rebuild-Nvidia-driver-cuda-cudnn-multi-use-anaconda.html" rel="alternate" type="text/html" title="Ubuntu18.04重装Nvidia驱动，cuda和cudnn，多用户使用anaconda" /><published>2020-02-17T00:00:00+08:00</published><updated>2020-02-17T00:00:00+08:00</updated><id>http://localhost:4000/2020/02/17/Ubuntu18.04-rebuild-Nvidia-driver-cuda-cudnn-multi-use-anaconda</id><content type="html" xml:base="http://localhost:4000/2020/02/17/Ubuntu18.04-rebuild-Nvidia-driver-cuda-cudnn-multi-use-anaconda.html">&lt;p&gt;最近手残升级了nvidia显卡驱动，导致cuda与驱动冲动，没办法只能重装了。
&lt;!--more--&gt;
配置信息：&lt;br /&gt;系统：Ubuntu18.04；显卡：Nvidia 2080Ti；驱动：Nvidia Driver 440.44；cuda：10.2；cudnn：7.6.5&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200108100525530.png&quot; alt=&quot;img&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;查看cuda 版本
cat /usr/local/cuda/version.txt&lt;/p&gt;

&lt;p&gt;查看cudnn 版本
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200108100752066-1581941094214.png&quot; alt=&quot;image-20200108100752066&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;重装显卡驱动&quot;&gt;重装显卡驱动&lt;/h2&gt;

&lt;h3 id=&quot;禁用nouveau驱动&quot;&gt;禁用nouveau驱动&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo vim /etc/modprobe.d/blacklist.conf&lt;/code&gt;
在文本最后添加：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;blacklist nouveau
options nouveau modeset=0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后执行：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo update-initramfs -u&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;重启机器后，执行以下命令，如果没有屏幕输出，说明禁用nouveau成功：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lsmod | grep nouveau&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;下载驱动&quot;&gt;下载驱动&lt;/h3&gt;

&lt;p&gt;官网下载地址：https://www.nvidia.cn/Download/index.aspx?lang=cn ，根据自己显卡的情况下载对应版本的显卡驱动。下载得到一个.run安装包，之后会用到。&lt;/p&gt;

&lt;h3 id=&quot;卸载旧驱动&quot;&gt;卸载旧驱动&lt;/h3&gt;

&lt;p&gt;重启后，使用快捷键进入文本模式，然后输入用户名密码就可：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Ctrl-Alt+F1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;执行以下命令禁用X-Window服务，否则无法安装显卡驱动：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo service lightdm stop&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;执行以下命令卸载原有显卡驱动：注意匹配自己下载的驱动版本&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get remove --purge nvidia*
sudo apt-get autoremove
sudo chmod +x NVIDIA-Linux-x86_64-4**.**.run
sudo ./NVIDIA-Linux-x86_64-4**.**.run --uninstall
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;安装新驱动&quot;&gt;安装新驱动&lt;/h3&gt;

&lt;p&gt;保险期间，再重启一遍。直接执行驱动文件即可安装新驱动，一直默认即可：&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo ./NVIDIA-Linux-x86_64-410.93.run
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;执行以下命令启动X-Window服务&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo service lightdm start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后执行重启命令，重启系统即可：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;reboot
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;重装cuda&quot;&gt;重装CUDA&lt;/h2&gt;

&lt;p&gt;因为重装后的驱动和原来CUDA版本还是不一样（如果之前安装了CUDA，可以用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nvcc -V&lt;/code&gt;试试，不行的话还是重装吧​🙂​）&lt;/p&gt;

&lt;p&gt;卸载CUDA执行的是CUDA自带的卸载脚本，读者要根据自己的cuda版本找到卸载脚本：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo /usr/local/cuda-10.0/bin/uninstall_cuda_10.0.pl&lt;/code&gt;
卸载之后，还有一些残留的文件夹，之前安装的是CUDA 8.0。可以一并删除：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo rm -rf /usr/local/cuda-10.0/&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;安装cuda&quot;&gt;安装CUDA&lt;/h2&gt;

&lt;h3 id=&quot;下载安装&quot;&gt;下载安装&lt;/h3&gt;

&lt;p&gt;在官网：&lt;a href=&quot;https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;amp;target_arch=x86_64&amp;amp;target_distro=Ubuntu&amp;amp;target_version=1604&amp;amp;target_type=runfilelocal&quot;&gt;CUDA下载页面&lt;/a&gt;，下载符合自己系统版本的CUDA。&lt;/p&gt;

&lt;p&gt;下载完成之后，给文件赋予执行权限：&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chmod +x cuda_*****_linux.run
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;执行安装包，开始安装：&lt;/p&gt;

&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./cuda_****_linux.run
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;CUDA10.2安装时会显示这样一个画面👇，不安装驱动了，注意把Driver去掉，否则会导致重复安装驱动&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jinluzhang.site/PublicPic/Pic/image-20200107223538310.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;配置环境变量&quot;&gt;配置环境变量&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export CUDA_HOME=/usr/local/cuda-10.2
export LD_LIBRARY_PATH=${CUDA_HOME}/lib64
export PATH=${CUDA_HOME}/bin:${PATH}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;安装cudnn&quot;&gt;安装CUDNN&lt;/h2&gt;

&lt;p&gt;CUDNN的下载官网：https://developer.nvidia.com/rdp/cudnn-download ，点击Download开始选择和CUDA10.2匹配的下载版本，选择&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cuDNN Library for Linux&lt;/code&gt;：&lt;/p&gt;

&lt;p&gt;对它进行解压，命令如下：&lt;/p&gt;

&lt;p&gt;tar -zxvf cudnn-10.0-linux-x64-v7.4.2.24.tgz&lt;/p&gt;

&lt;p&gt;解压之后可以得到以下文件：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;cuda/include/cudnn.h
cuda/NVIDIA_SLA_cuDNN_Support.txt
cuda/lib64/libcudnn.so
cuda/lib64/libcudnn.so.7
cuda/lib64/libcudnn.so.7.4.2
cuda/lib64/libcudnn_static.a&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;使用以下两条命令复制这些文件到CUDA目录下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cp cuda/lib64/* /usr/local/cuda-10.0/lib64/
cp cuda/include/* /usr/local/cuda-10.0/include/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;拷贝完成之后，可以使用以下命令查看CUDNN的版本信息：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;安装anaconda3&quot;&gt;安装Anaconda3&lt;/h2&gt;

&lt;p&gt;先去官方地址下载好对应的安装包&lt;a href=&quot;https://www.anaconda.com/download/#linux&quot;&gt;Ubuntu - anaconda 下载地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;然后直接安装anaconda ：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bash ~/Downloads/Anaconda3-5.2.0-Linux-x86_64.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;安装过程中看到&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Welcome to Anaconda3 5.2.0
In order to continue the installation process, please review the license
agreement. (为了继续安装过程，请审核许可证。协议。)
Please, press ENTER to continue&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;直接按enter查看协议，然后一直enter下去，&lt;/p&gt;

&lt;p&gt;然后看到&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;Do you accept the license terms? [yes&lt;/td&gt;
        &lt;td&gt;no]（你接受许可证条款吗?）&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;直接输入yes 然后按enter，进入下一步&lt;/p&gt;

&lt;p&gt;接下来会提示安装地址：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Anaconda3 will now be installed into this location:
/home/user/anaconda3&lt;/p&gt;

  &lt;p&gt;Press ENTER to confirm the location
Press CTRL-C to abort the installation
Or specify a different location below&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;建议默认即可，
按enter继续下一步，注意这里按ctrl + c 直接会终止安装。
接下来先等待安装即可。
看到&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Thank you for installing Anaconda3!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;表示安装成功。&lt;/p&gt;

&lt;h3 id=&quot;添加环境变量&quot;&gt;添加环境变量&lt;/h3&gt;

&lt;p&gt;anaconda会自动将环境变量添加到PATH里面，如果后面你发现输出conda
提示没有该命令，那么你需要source ~/.bashrc 这样就是更新环境变量，就可以正常使用了。
如果发现这样还是没用，那么需要收到添加环境变量
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo vim ~/.basrc&lt;/code&gt; 文件，在最后面加上
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;export PATH=/home/user/anaconda3/bin:$PATH&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;保存退出后：source ~/.bashrc
再次输入conda list测试看看，应该就是没有问题啦！&lt;/p&gt;

&lt;h2 id=&quot;多用户使用conda&quot;&gt;多用户使用conda&lt;/h2&gt;

&lt;p&gt;注意我在user用户下安装配置的conda，怎么在其他用户里使用conda呢？直接使用会报错没有conda命令&lt;/p&gt;

&lt;p&gt;做如下配置：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su another_user
sudo vim ~/.basrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;最后一行加上conda安装位置的环境变量：export PATH=/home/user/anaconda3/bin:$PATH&lt;/p&gt;

&lt;p&gt;保存退出后：source ~/.bashrc&lt;/p&gt;

&lt;p&gt;如果使用conda activate命令显示没有初始化这样的错误，运行下面代码：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/anaconda3/etc/profile.d/conda.sh
conda activate my_env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Jinlu Zhang</name><email>Jinluzhang1126@163.com</email></author><category term="enviroment-setup" /><summary type="html">最近手残升级了nvidia显卡驱动，导致cuda与驱动冲动，没办法只能重装了。</summary></entry><entry><title type="html">Hello World!</title><link href="http://localhost:4000/2020/02/16/hello-world.html" rel="alternate" type="text/html" title="Hello World!" /><published>2020-02-16T00:00:00+08:00</published><updated>2020-02-16T00:00:00+08:00</updated><id>http://localhost:4000/2020/02/16/hello-world</id><content type="html" xml:base="http://localhost:4000/2020/02/16/hello-world.html">&lt;p&gt;Hi everyone, welcome come to my blog website.:wink:&lt;/p&gt;

&lt;p&gt;I start this blog website by myself and Powered by &lt;a href=&quot;http://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://github.com/kitian616/jekyll-TeXt-theme&quot;&gt;TeXt Theme&lt;/a&gt;. Thanks the &lt;a href=&quot;https://github.com/kitian616&quot;&gt;author&lt;/a&gt; of this theme.&lt;/p&gt;

&lt;p&gt;If you like my blog theme, Just take it away &lt;a href=&quot;https://github.com/JinluZhang1126/jinluzhang1126.github.io/tree/template&quot;&gt;here&lt;/a&gt;! It is yours now! :laughing:
&lt;!--more--&gt;
This blog is mainly for recording my &lt;strong&gt;research and learning life&lt;/strong&gt; in the future.&lt;/p&gt;

&lt;p&gt;I will try my best to write my blog with English, but you know, my English is not solid enough to express myself:pensive:. Thus i will firstly write logs with Chinese. If you want any article’s English version or have any qusetion, just comment to me in the comment area at each article’s footer.&lt;/p&gt;

&lt;p&gt;I am Jinlu Zhang. I am coming to a new world! :smiley:&lt;/p&gt;</content><author><name>Jinlu Zhang</name><email>Jinluzhang1126@163.com</email></author><summary type="html">Hi everyone, welcome come to my blog website.:wink: I start this blog website by myself and Powered by Jekyll &amp;amp; TeXt Theme. Thanks the author of this theme. If you like my blog theme, Just take it away here! It is yours now! :laughing:</summary></entry></feed>